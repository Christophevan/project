{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import requests\n",
      "from urlparse import parse_qsl\n",
      "from pattern import web\n",
      "import matplotlib.pyplot as plt\n",
      "from bs4 import BeautifulSoup as bs \n",
      "from collections import defaultdict\n",
      "import pandas as pd\n",
      "from operator import itemgetter\n",
      "from datetime import date as make_date\n",
      "\n",
      "#Used in get player data\n",
      "import urllib2\n",
      "import mechanize\n",
      "\n",
      "# Set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Team Data Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we implement functions to scrape team data from the hoopdata site"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_team_names()\n",
      "\tGet the team names\n",
      "\n",
      "Parameters:\n",
      "\tNone\n",
      "    \n",
      "Returns:\n",
      "\tteam_data: A list with the abreviated team name\n",
      "\"\"\"\n",
      "def get_team_names():\n",
      "    url = 'http://www.hoopdata.com/teamff.aspx?yr=2012&type=pg'\n",
      "    txt = requests.get(url).text\n",
      "\n",
      "    #Import data to beautiful soup\n",
      "    soup = bs(txt)\n",
      "        \n",
      "    #Get all tables and accumulate a list of sub_headers\n",
      "    tables = soup.find_all('table', id='MyGridView')\n",
      "    sub_headers = [header.a.string for header in tables[5].find_all('th')[1:]]\n",
      "    \n",
      "    #Get the relevant table and table rows\n",
      "    tab = soup.find_all('table', id='MyGridView')[5]\n",
      "    tabrow = tab.find_all('tr', onmouseover = \"this.style.backgroundColor = '#FF8800';\")\n",
      "    \n",
      "    #Iterate through each row, to get the team names\n",
      "    \n",
      "    teams = []\n",
      "    for row in tabrow:\n",
      "        #Get all columns in this row\n",
      "        col = row.find_all('td')\n",
      "            \n",
      "        #Make a list of the team names\n",
      "        teams.append(str(col[0].a.string))\n",
      "        \n",
      "    return teams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_team_data()\n",
      "\tGet the team data\n",
      "\n",
      "Parameters:\n",
      "\tNone\n",
      "    \n",
      "Returns:\n",
      "\tteam_data: A dict containing team data keyed on abbreviated team name\n",
      "\"\"\"\n",
      "def get_team_data():\n",
      "    \n",
      "    #Define category headers\n",
      "    headers = ['overall','efg','ftr','tor','orr']\n",
      "            \n",
      "    #Get list of team names, years\n",
      "    teams = get_team_names()\n",
      "    years = range(2007, 2013)\n",
      "    \n",
      "    #Initialize the dict we will be returning\n",
      "    team_data = defaultdict(dict)\n",
      "    \n",
      "    #Iteratate over years for which there is data available\n",
      "    for year in years:\n",
      "        #Get text from hoopdata page, concating year to be scraped\n",
      "        url = 'http://www.hoopdata.com/teamff.aspx?yr=' + str(year) + '&type=pg'\n",
      "        txt = requests.get(url).text\n",
      "\n",
      "        #Import data to beautiful soup\n",
      "        soup = bs(txt)\n",
      "        \n",
      "        #Get all tables and accumulate a list of sub_headers\n",
      "        tables = soup.find_all('table', id='MyGridView')\n",
      "        sub_headers = [header.a.string for header in tables[5].find_all('th')[1:]]\n",
      "        \n",
      "        #Get the relevant table and table rows\n",
      "        tab = soup.find_all('table', id='MyGridView')[5]\n",
      "        tabrow = tab.find_all('tr', onmouseover = \"this.style.backgroundColor = '#FF8800';\")\n",
      "        \n",
      "        #Iterate through each row, scraping the data\n",
      "        for row in tabrow:\n",
      "            temp_dict = defaultdict(dict)\n",
      "            \n",
      "            #Get all columns in this row\n",
      "            col = row.find_all('td')\n",
      "            \n",
      "            #Store the team name\n",
      "            team = str(col[0].a.string)\n",
      "            \n",
      "            #Iterate over the columns storing the data in the relevant category\n",
      "            for i,val in enumerate(col[1:]):\n",
      "                \n",
      "                # Comments here follow the follow notation:\n",
      "                # Category Header - Subheader1, Subheader2, Subheader3\n",
      "                \n",
      "                # Overall - OffEff, DefEff, Diff\n",
      "                if i<=2:\n",
      "                    temp_dict[headers[0]][sub_headers[i]] = val.string\n",
      "                    \n",
      "                # EFG% - Own, Opp, Diff\n",
      "                elif i<=5:\n",
      "                    temp_dict[headers[1]][sub_headers[i]] = val.string\n",
      "                    \n",
      "                # FTR - Own, Opp, Diff\n",
      "                elif i<=8:\n",
      "                    temp_dict[headers[2]][sub_headers[i]] = val.string\n",
      "                \n",
      "                # TOR - Own, Opp, Diff\n",
      "                elif i<=11:\n",
      "                    temp_dict[headers[3]][sub_headers[i]] = val.string\n",
      "                # ORR - Own, Opp, Diff\n",
      "                elif i<=14: \n",
      "                    temp_dict[headers[4]][sub_headers[i]] = val.string\n",
      "                    \n",
      "            #Account for franchise move\n",
      "            if team == 'SEA':\n",
      "                team = 'OKC'\n",
      "            \n",
      "            # Add the accumulated data to the finalized dict\n",
      "            team_data[team][year] = temp_dict\n",
      "    \n",
      "    return team_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "team_data = get_team_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Game Data Collection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These functions get the team's game scores results from throughout the season"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_abrv_name(unabrv_name)\n",
      "\tGet the abviation for a given name\n",
      "\n",
      "Parameters:\n",
      "\tunabrv_name: The unabreviated name of a basketball team\n",
      "    \n",
      "Returns:\n",
      "\tabrv_name: A string of the abreviation for the team name\n",
      "\"\"\"\n",
      "def get_abrv_name(unabrv_name):\n",
      "    abrvs = {'Atlanta Hawks'                     : 'ATL',\n",
      "             'St. Louis Hawks'                   : 'ATL', #Franchise Relocation\n",
      "             'Milwaukee Hawks'                   : 'ATL', #Franchise Relocation\n",
      "             'Boston Celtics'                    : 'BOS',\n",
      "             'Brooklyn Nets'                     : 'NJN',\n",
      "             'New Jersey Nets'                   : 'NJN', #Franchise Relocation\n",
      "             'New York Nets'                     : 'NJN', #Franchise Relocation\n",
      "             'Charlotte Bobcats'                 : 'CHA',\n",
      "             'Chicago Bulls'                     : 'CHI',\n",
      "             'Cleveland Cavaliers'               : 'CLE',\n",
      "             'Dallas Mavericks'                  : 'DAL',\n",
      "             'Denver Nuggets'                    : 'DEN',\n",
      "             'Detroit Pistons'                   : 'DET',\n",
      "             'Golden State Warriors'             : 'GSW',\n",
      "             'Philadelphia Warriors'             : 'GSW', #Franchise Relocation\n",
      "             'San Francisco Warriors'            : 'GSW', #Franchise Relocation\n",
      "             'Houston Rockets'                   : 'HOU',\n",
      "             'San Diego Rockets'                 : 'HOU', #Franchise Relocation\n",
      "             'Indiana Pacers'                    : 'IND',\n",
      "             'Los Angeles Clippers'              : 'LAC',\n",
      "             'Buffalo Braves'                    : 'LAC', #Franchise Relocation\n",
      "             'San Diego Clippers'                : 'LAC', #Franchise Rename\n",
      "             'Los Angeles Lakers'                : 'LAL',\n",
      "             'Minneapolis Lakers'                : 'LAL', #Franchise Relocation\n",
      "             'Memphis Grizzlies'                 : 'MEM',\n",
      "             'Vancouver Grizzlies'               : 'MEM', #Franchise Relocation\n",
      "             'Miami Heat'                        : 'MIA',\n",
      "             'Milwaukee Bucks'                   : 'MIL',\n",
      "             'Minnesota Timberwolves'            : 'MIN',\n",
      "             'New Orleans Hornets'               : 'NOR',\n",
      "             'New Orleans Pelicans'              : 'NOR', #Franchise Rename\n",
      "             'New Orleans/Oklahoma City Hornets' : 'NOR', #Franchise Relocation\n",
      "             'Charlotte Hornets'                 : 'NOR', #Franchise Relocation\n",
      "             'New York Knicks'                   : 'NYK',\n",
      "             'Oklahoma City Thunder'             : 'OKC', #Franchise Relocation\n",
      "             'Seattle SuperSonics'               : 'OKC',\n",
      "             'Orlando Magic'                     : 'ORL',\n",
      "             'Philadelphia 76ers'                : 'PHI',\n",
      "             'Syracuse Nationals'                : 'PHI', #Franchise Relocation\n",
      "             'Phoenix Suns'                      : 'PHO',\n",
      "             'Portland Trail Blazers'            : 'POR',\n",
      "             'Sacramento Kings'                  : 'SAC',\n",
      "             'Cincinnati Royals'                 : 'SAC', #Franchise Relocation\n",
      "             'Rochester Royals'                  : 'SAC', #Franchise Relocation\n",
      "             'Kansas City-Omaha Kings'           : 'SAC', #Franchise Relocation\n",
      "             'Kansas City Kings'                 : 'SAC', #Franchise Relocation\n",
      "             'San Antonio Spurs'                 : 'SAS', \n",
      "             'Toronto Raptors'                   : 'TOR',\n",
      "             'Utah Jazz'                         : 'UTH',\n",
      "             'New Orleans Jazz'                  : 'UTH', #Franchise Relocation\n",
      "             'Washington Wizards'                : 'WAS',\n",
      "             'Chicago Packers'                   : 'WAS', #Franchise Rename\n",
      "             'Chicago Zephyrs'                   : 'WAS', #Franchise Rename              \n",
      "             'Baltimore Bullets'                 : 'WAS', #Franchise Rename             \n",
      "             'Capital Bullets'                   : 'WAS', #Franchise Rename\n",
      "             'Washington Bullets'                : 'WAS'} #Franchise Rename\n",
      "\n",
      "    \n",
      "    #Return abreviated name\n",
      "    return str(abrvs[unabrv_name])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_game_data(year)\n",
      "\tGet the result of each game for a given year\n",
      "\n",
      "Parameters:\n",
      "\tyear: The year to scrape game results from\n",
      "    \n",
      "Returns:\n",
      "\tgame_data: A dict containing a tuple of the date and final score of the game keyed on the teams playing. That is:\n",
      "    {(team1, team2): (team1_score, team2_score)}\n",
      "\"\"\"\n",
      "def get_game_data(year):\n",
      "    \n",
      "    #Initialize the dict we will be returning\n",
      "    game_data = defaultdict(list)\n",
      "    \n",
      "    #Get text from website, concating year to be scraped\n",
      "    url = 'http://www.basketball-reference.com/leagues/NBA_' + str(year) + '_games.html#games::none'\n",
      "    txt = requests.get(url).text\n",
      "\n",
      "    #Import data to beautiful soup\n",
      "    soup = bs(txt, 'html.parser') \n",
      "    \n",
      "    #Get desired table and iterable of rows\n",
      "    table = soup.find('table', id='games')\n",
      "    rows = table.find_all('tr')[1:]\n",
      "    \n",
      "    #Iterate over the rows of the table, getting the name and scores\n",
      "    for row in rows:\n",
      "        #Find all data lines in each table row\n",
      "        lines = row.find_all('td')\n",
      "\n",
      "        #Get the date of each game by parsing the query url\n",
      "        query_url = lines[0].a['href'].split('?')[1]\n",
      "        date_parse = parse_qsl(query_url)\n",
      "        get_date_info = itemgetter(1)\n",
      "        \n",
      "        # Get the date values, cast to integer, and create date in standard notation\n",
      "        month, day, yr = map(get_date_info, date_parse)\n",
      "        date = make_date(int(yr), int(month), int(day))\n",
      "        \n",
      "        #Get visitor information\n",
      "        visit =  str(lines[2].text)\n",
      "        vist_score = int(lines[3].text)\n",
      "        \n",
      "        #Get home team info\n",
      "        home = str(lines[4].text)\n",
      "        home_score = int(lines[5].text)\n",
      "        \n",
      "        #Convert full names to abreviated names for keying\n",
      "        home_abrv = get_abrv_name(home)\n",
      "        vist_abrv = get_abrv_name(visit)\n",
      "        \n",
      "        #Save the score data\n",
      "        game_data[(home_abrv, vist_abrv)].append((date, home_score, vist_score))\n",
      "\n",
      "    return game_data\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "game_data = get_game_data(2013)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Get League Standings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_league_standings(year)\n",
      "\tGet the league standings for the year requested\n",
      "\n",
      "Parameters:\n",
      "\tyear: The year to collect standings from\n",
      "    \n",
      "Returns:\n",
      "\tgame_data: A dict containing league wide standings keyed on the abreviated team name. Specifically:\n",
      "    {abrv_team_name: league_standing}\n",
      "\"\"\"\n",
      "def get_league_standings(year):\n",
      "    #Initialize the dict we will be returning\n",
      "    league_standings = {}\n",
      "    \n",
      "    #Get text from website, concating year to be scraped\n",
      "    url = 'http://www.basketball-reference.com/leagues/NBA_' + str(year) + '_standings.html'\n",
      "    txt = requests.get(url).text\n",
      "\n",
      "    #Import data to beautiful soup\n",
      "    soup = bs(txt, 'html.parser') \n",
      "    \n",
      "    #Get desired table and iterable of rows\n",
      "    standings_table = soup.find('table', id='expanded-standings')\n",
      "    rows = standings_table.tbody.find_all('tr')\n",
      "    \n",
      "    #Iterate over the rows of the table, getting the name and scores\n",
      "    for rnk, row in enumerate(rows):\n",
      "    \n",
      "        #Get team name and convert to abreviated name\n",
      "        unabrv_name = str(row.a.text)\n",
      "        abrv_name = get_abrv_name(unabrv_name)\n",
      "        \n",
      "        #Calculate and save rank (adjust for 0-indexing)\n",
      "        league_standings[abrv_name] = rnk + 1\n",
      "        \n",
      "    return league_standings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 320
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for year in range(1960, 2013):\n",
      "    league_standings = get_league_standings(year)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 321
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Player Data Collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is a helper function to check if a string contains digits and is used to eliminate some strings captured that are not names \n",
      "def contains_digits(d):\n",
      "    _digits = re.compile('\\d')\n",
      "    return bool(_digits.search(d))\n",
      "\n",
      "#This function scrapes the player data page\n",
      "def fplayerstat(soup4):\n",
      "    for each in soup4.find_all('table')[2].find_all('tr')[1:]:\n",
      "\n",
      "        #Finds name of the player. \n",
      "        if contains_digits(each.td.text):\n",
      "            continue\n",
      "        else:\n",
      "            name = each.td.text\n",
      "        \n",
      "        #Adds first statistic playerdict since this is formatted differently. \n",
      "        #Using name and statistic name as keys. \n",
      "        try:\n",
      "            playerdict[name][list_attr[1]] =  each.td.next_sibling.a.string\n",
      "        except:\n",
      "            pass \n",
      "        \n",
      "        #Adds statistics to the dictionary. Using same keys as above. \n",
      "        counter = 2\n",
      "        while True: \n",
      "            try: \n",
      "                playerdict[name][list_attr[counter]] = each.find_all('td')[counter].text\n",
      "                counter = counter +1 \n",
      "            except:\n",
      "                break\n",
      "                \n",
      "    return playerdict \n",
      "\n",
      "#This traverses through the Javascript do_PostBack and returns the html of the page. \n",
      "def getpages(num):\n",
      "    #Gets form\n",
      "    br = mechanize.Browser()\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    response = br.open(\"http://hoopdata.com/advancedstats.aspx\")\n",
      "    html = response.read()\n",
      "    br.select_form(nr=0)\n",
      "    \n",
      "    #Sets form parameters\n",
      "    br.set_all_readonly(False)           \n",
      "    br[\"__EVENTTARGET\"] = 'MyGridView'\n",
      "    br[\"__EVENTARGUMENT\"] = 'Page$' + str(num)\n",
      "    \n",
      "    for control in br.form.controls:           \n",
      "       if control.type == \"submit\":\n",
      "           control.disabled = True\n",
      "    \n",
      "    #Submits form parameters and gets page \n",
      "    response = br.submit()\n",
      "    page = bs(response)\n",
      "    \n",
      "    return page "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 379
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Returns dict with player data\n",
      "def get_playerdict():\n",
      "    url=\"http://hoopdata.com/advancedstats.aspx\"\n",
      "    page=urllib2.urlopen(url)\n",
      "    soup2 = bs(page.read())\n",
      "    \n",
      "    # This creates a list of the statistic names. This will later be used as keys. \n",
      "    list_attr = [] \n",
      "    for each in soup2.find_all('table')[2].find_all('tr',align = 'center')[0].find_all('th'):\n",
      "        list_attr.append(each.get_text())\n",
      "    \n",
      "    playerdict = defaultdict(dict) \n",
      "    \n",
      "    #Creating a dictionary for the first page. Later pages will be merged onto this. \n",
      "    playerdict = fplayerstat(soup2) \n",
      "    \n",
      "    #This finds the number of pages there are. Creates list_page of the page numbers. \n",
      "    list_page = [] \n",
      "    for each in soup2.find_all('a',href=re.compile(\"javascript:__doPostBack\\('MyGridView','Page\")):\n",
      "        list_page.append(int(each.text)) \n",
      "    \n",
      "    #Creates num which is the page number of the last page. \n",
      "    num = max(list_page)\n",
      "    \n",
      "    #Creates list_pageinfo which is a list of the html of the pages. \n",
      "    list_pageinfo = [] \n",
      "    for i in range(2,num+1): \n",
      "        list_pageinfo.append(getpages(i))        \n",
      "    \n",
      "    #Scrapes each page with fplayerstat() and adds it onto our first dictionary, playerdict.    \n",
      "    for each in list_pageinfo:\n",
      "        temp = fplayerstat(each)\n",
      "        playerdict.update(temp) \n",
      "        \n",
      "    return playerdict\n",
      "     \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 380
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "playerdict = get_playerdict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 381
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 382
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}