{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import json\n",
      "import numpy as np\n",
      "import networkx as nx\n",
      "import requests\n",
      "from pattern import web\n",
      "import matplotlib.pyplot as plt\n",
      "from bs4 import BeautifulSoup as bs \n",
      "from collections import defaultdict\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "# Set some nicer defaults for matplotlib\n",
      "from matplotlib import rcParams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Team Data Scraper"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we implement functions to scrape team data from the hoopdata site"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_team_names()\n",
      "\tGet the team names\n",
      "\n",
      "Parameters:\n",
      "\tNone\n",
      "    \n",
      "Returns:\n",
      "\tteam_data: A list with the abreviated team name\n",
      "\"\"\"\n",
      "def get_team_names():\n",
      "    url = 'http://www.hoopdata.com/teamff.aspx?yr=2012&type=pg'\n",
      "    txt = requests.get(url).text\n",
      "\n",
      "    #Import data to beautiful soup\n",
      "    soup = bs(txt)\n",
      "        \n",
      "    #Get all tables and accumulate a list of sub_headers\n",
      "    tables = soup.find_all('table', id='MyGridView')\n",
      "    sub_headers = [header.a.string for header in tables[5].find_all('th')[1:]]\n",
      "    \n",
      "    #Get the relevant table and table rows\n",
      "    tab = soup.find_all('table', id='MyGridView')[5]\n",
      "    tabrow = tab.find_all('tr', onmouseover = \"this.style.backgroundColor = '#FF8800';\")\n",
      "    \n",
      "    #Iterate through each row, to get the team names\n",
      "    \n",
      "    teams = []\n",
      "    for row in tabrow:\n",
      "        #Get all columns in this row\n",
      "        col = row.find_all('td')\n",
      "            \n",
      "        #Make a list of the team names\n",
      "        teams.append(str(col[0].a.string))\n",
      "        \n",
      "    return teams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Function: get_team_data()\n",
      "\tGet the team data\n",
      "\n",
      "Parameters:\n",
      "\tNone\n",
      "    \n",
      "Returns:\n",
      "\tteam_data: A dataframe containing team data keyed on abbreviated team name\n",
      "\"\"\"\n",
      "def get_team_data():\n",
      "    \n",
      "    #Define category headers\n",
      "    headers = ['overall','efg','ftr','tor','orr']\n",
      "            \n",
      "    #Get list of team names, years\n",
      "    teams = get_team_names()\n",
      "    years = range(2007, 2013)\n",
      "    \n",
      "    #Initialize the dict we will be returning\n",
      "    team_data = defaultdict(dict)\n",
      "    \n",
      "    #Iteratate over years for which there is data available\n",
      "    for year in years:\n",
      "        #Get text from hoopdata page, concating year to be scraped\n",
      "        url = 'http://www.hoopdata.com/teamff.aspx?yr=' + str(year) + '&type=pg'\n",
      "        txt = requests.get(url).text\n",
      "\n",
      "        #Import data to beautiful soup\n",
      "        soup = bs(txt)\n",
      "        \n",
      "        #Get all tables and accumulate a list of sub_headers\n",
      "        tables = soup.find_all('table', id='MyGridView')\n",
      "        sub_headers = [header.a.string for header in tables[5].find_all('th')[1:]]\n",
      "        \n",
      "        #Get the relevant table and table rows\n",
      "        tab = soup.find_all('table', id='MyGridView')[5]\n",
      "        tabrow = tab.find_all('tr', onmouseover = \"this.style.backgroundColor = '#FF8800';\")\n",
      "        \n",
      "        #Iterate through each row, scraping the data\n",
      "        for row in tabrow:\n",
      "            try:\n",
      "                temp_dict = defaultdict(dict)\n",
      "                #temp_dict = pd.DataFrame()\n",
      "                \n",
      "                #Get all columns in this row\n",
      "                col = row.find_all('td')\n",
      "                \n",
      "                \n",
      "                #Store the team name\n",
      "                team = str(col[0].a.string)\n",
      "                \n",
      "                #Iterate over the columns storing the data in the relevant category\n",
      "                for i,val in enumerate(col[1:]):\n",
      "                    \n",
      "                    # Comments here follow the follow notation:\n",
      "                    # Category Header - Subheader1, Subheader2, Subheader3\n",
      "                    \n",
      "                    # Overall - OffEff, DefEff, Diff\n",
      "                    if i<=2:\n",
      "                        temp_dict[headers[0]][sub_headers[i]] = val.string\n",
      "                        \n",
      "                    # EFG% - Own, Opp, Diff\n",
      "                    elif i<=5:\n",
      "                        temp_dict[headers[1]][sub_headers[i]] = val.string\n",
      "                        \n",
      "                    # FTR - Own, Opp, Diff\n",
      "                    elif i<=8:\n",
      "                        temp_dict[headers[2]][sub_headers[i]] = val.string\n",
      "                    \n",
      "                    # TOR - Own, Opp, Diff\n",
      "                    elif i<=11:\n",
      "                        temp_dict[headers[3]][sub_headers[i]] = val.string\n",
      "                    # ORR - Own, Opp, Diff\n",
      "                    elif i<=14: \n",
      "                        temp_dict[headers[4]][sub_headers[i]] = val.string\n",
      "                \n",
      "                # Add the accumulated data to the finalized dict\n",
      "                team_data[team][year] = temp_dict\n",
      "            except:\n",
      "                # Skip the row if the data is malformed\n",
      "                pass\n",
      "        \n",
      "    return team_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "team_data = get_team_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    }
   ],
   "metadata": {}
  }
 ]
}